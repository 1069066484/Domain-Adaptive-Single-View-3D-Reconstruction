{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from chamfer_distance import ChamferDistance\n",
    "from torch.autograd import Variable\n",
    "import glob\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = glob.glob(\"/datasets/cs253-wi20-public/ShapeNet_pointclouds/*/*/*2048.npy\")\n",
    "\n",
    "class PointCloudDataset(Dataset):\n",
    "\n",
    "    def __init__(self, lis= None):\n",
    "        \n",
    "        point_clouds = []\n",
    "        for file_name in lis:\n",
    "\n",
    "            points = np.load(file_name)\n",
    "            point_clouds.append(points)\n",
    "\n",
    "        self.point_clouds = np.array(point_clouds, dtype='float64')\n",
    "        self.point_clouds = np.transpose(self.point_clouds, (0, 2, 1))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.point_clouds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.point_clouds[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tnet(nn.Module):\n",
    "    def __init__(self, k=3):\n",
    "        super().__init__()\n",
    "        self.k=k\n",
    "        self.conv1 = nn.Conv1d(k,64,1)\n",
    "        self.conv2 = nn.Conv1d(64,128,1)\n",
    "        self.conv3 = nn.Conv1d(128,1024,1)\n",
    "        self.fc1 = nn.Linear(1024,512)\n",
    "        self.fc2 = nn.Linear(512,256)\n",
    "        self.fc3 = nn.Linear(256,k*k)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "       \n",
    "\n",
    "    def forward(self, input):\n",
    "        # input.shape == (bs,n,3)\n",
    "        bs = input.size(0)\n",
    "        xb = F.relu(self.bn1(self.conv1(input)))\n",
    "        xb = F.relu(self.bn2(self.conv2(xb)))\n",
    "        xb = F.relu(self.bn3(self.conv3(xb)))\n",
    "        xb = nn.MaxPool1d(xb.size(-1))(xb)\n",
    "        xb = nn.Flatten(1)(xb)\n",
    "        xb = F.relu(self.bn4(self.fc1(xb)))\n",
    "        xb = F.relu(self.bn5(self.fc2(xb)))\n",
    "      \n",
    "      #initialize as identity\n",
    "        init = torch.eye(self.k, requires_grad=True).repeat(bs,1,1)\n",
    "        if xb.is_cuda:\n",
    "            init=init.cuda()\n",
    "        matrix = self.fc3(xb).view(-1,self.k,self.k) + init\n",
    "        return matrix\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input_transform = Tnet(k=3)\n",
    "        self.feature_transform = Tnet(k=64)\n",
    "        self.fc1 = nn.Conv1d(3,64,1)\n",
    "        self.fc2 = nn.Conv1d(64,64,1) \n",
    "        self.fc4 = nn.Conv1d(64,128,1)\n",
    "        self.fc5 = nn.Conv1d(128,1024,1)\n",
    "\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.bn4 = nn.BatchNorm1d(128)\n",
    "        self.bn5 = nn.BatchNorm1d(1024)\n",
    "\n",
    "    def forward(self, input):\n",
    "        n_pts = input.size()[2]\n",
    "        matrix3x3 = self.input_transform(input)\n",
    "        xb = torch.bmm(torch.transpose(input,1,2), matrix3x3).transpose(1,2)\n",
    "        xb = F.relu(self.bn1(self.fc1(xb)))\n",
    "        xb = F.relu(self.bn2(self.fc2(xb)))\n",
    "        matrix128x128 = self.feature_transform(xb)\n",
    "        xb = torch.bmm(torch.transpose(xb,1,2), matrix128x128).transpose(1,2) \n",
    "        xb = F.relu(self.bn4(self.fc4(xb)))\n",
    "        xb = self.bn5(self.fc5(xb))\n",
    "        xb = nn.MaxPool1d(xb.size(-1))(xb)        \n",
    "        \n",
    "        return xb\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128,2048*3)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        input = input.view(input.size(0), -1)\n",
    "        out = F.relu(self.bn1(self.fc1(input)))\n",
    "        out = F.relu(self.bn2(self.fc2(out)))\n",
    "        out = F.relu(self.bn3(self.fc3(out)))\n",
    "        out =  torch.tanh(self.fc4(out))\n",
    "        return out.view(-1, 3, 2048)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping():\n",
    "    \"\"\"\n",
    "    Early Stopping to terminate training early under certain conditions\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, min_delta=0, patience=50):\n",
    "        \n",
    "        \"\"\"\n",
    "        EarlyStopping callback to exit the training loop if training or\n",
    "        validation loss does not improve by a certain amount for a certain\n",
    "        number of epochs\n",
    "        Arguments\n",
    "        ---------\n",
    "        min_delta : float\n",
    "            minimum change in monitored value to qualify as improvement.\n",
    "            This number should be positive.\n",
    "        patience : integer\n",
    "            number of epochs to wait for improvment before terminating.\n",
    "            the counter be reset after each improvment\n",
    "        \"\"\"\n",
    "        \n",
    "        self.min_delta = min_delta\n",
    "        self.patience = patience\n",
    "        self.wait = 0\n",
    "        self.best_loss = 1e-15\n",
    "        self.stopped_epoch = 0\n",
    "\n",
    "    def on_train_begin(self):\n",
    "        self.wait = 0\n",
    "        self.best_loss = 1e15\n",
    "\n",
    "    def on_epoch_end(self, epoch, current_loss):\n",
    "\n",
    "        if current_loss is None:\n",
    "            pass\n",
    "        else:\n",
    "            if (current_loss - self.best_loss) < -self.min_delta:\n",
    "                self.best_loss = current_loss\n",
    "                self.wait = 1\n",
    "            else:\n",
    "                if self.wait >= self.patience:\n",
    "                    return True\n",
    "                self.wait += 1\n",
    "        \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Encoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Tnet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv1d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm1d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Decoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/1000], loss:12.9899\n",
      "epoch [2/1000], loss:11.9559\n"
     ]
    }
   ],
   "source": [
    "point_cloud_dataset = PointCloudDataset(l)\n",
    "dataloader = DataLoader(point_cloud_dataset, batch_size=32, shuffle=True)\n",
    "#enc = Encoder()\n",
    "#dec = Decoder()\n",
    "enc = torch.load('encoder')\n",
    "dec = torch.load('decoder')\n",
    "chamferDist = ChamferDistance()\n",
    "#early_stopping = EarlyStopping(patience=50)\n",
    "\n",
    "num_epochs = 1000\n",
    "learning_rate = 1e-3\n",
    "\n",
    "optimizere = torch.optim.Adam(enc.parameters(), lr=learning_rate)\n",
    "optimizerd = torch.optim.Adam(dec.parameters(), lr=learning_rate)\n",
    "if torch.cuda.is_available():\n",
    "    enc = enc.cuda()\n",
    "    dec = dec.cuda()\n",
    "loss_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "   # if epoch == 0:\n",
    "  #      early_stopping.on_train_begin()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for data in dataloader:\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            \n",
    "        train_output = enc(data.float())\n",
    "        out= dec(train_output)\n",
    "        dist1, dist2 = chamferDist(out.float(), data.float())\n",
    "        loss = (torch.mean(dist1)) + (torch.mean(dist2))\n",
    "\n",
    "        optimizere.zero_grad()\n",
    "        optimizerd.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizere.step()\n",
    "        optimizerd.step()\n",
    "        \n",
    "        running_loss += loss.data.detach() \n",
    "    \n",
    "    loss_list.append(running_loss / data.shape[0])\n",
    "    \n",
    "  #  if early_stopping.on_epoch_end(epoch + 1, running_loss):\n",
    "   #     print('epoch [{}/{}], loss:{:.4f}'.format(epoch + 1, num_epochs, loss_list[-1]))\n",
    "  #      print('Terminated Training for Early Stopping at Epoch %04i' % (epoch + 1))\n",
    "    torch.save(enc, 'encoder')\n",
    "    torch.save(dec, 'decoder')\n",
    "            \n",
    "    print('epoch [{}/{}], loss:{:.4f}'.format(epoch + 1, num_epochs, loss_list[-1]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
